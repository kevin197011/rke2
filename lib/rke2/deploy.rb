# Copyright (c) 2025 Kk
#
# This software is released under the MIT License.
# https://opensource.org/licenses/MIT


# frozen_string_literal: true

require 'yaml'
require 'fileutils'
require 'net/ssh'
require 'net/scp'
require 'logger'
require 'stringio'

class Deploy
  def initialize(config_file= 'config.yml')
    @config = YAML.load_file(config_file)
    @token = @config['token']
    @lb_ip = @config['loadbalancer_ip']
    @nodes = @config['nodes']
    @logger = Logger.new('deploy.log')

    # æŒ‰è§’è‰²åˆ†ç»„èŠ‚ç‚¹
    @server_nodes = @nodes.select { |node| node['role'] == 'server' }
    @agent_nodes = @nodes.select { |node| node['role'] == 'agent' }
    @lb_nodes = @nodes.select { |node| node['role'] == 'lb' }
  end

  def run
    log('ğŸš€ å¼€å§‹ RKE2 é›†ç¾¤éƒ¨ç½²')
    log("æœåŠ¡å™¨èŠ‚ç‚¹: #{@server_nodes.size} ä¸ª")
    log("å·¥ä½œèŠ‚ç‚¹: #{@agent_nodes.size} ä¸ª")
    log("è´Ÿè½½å‡è¡¡èŠ‚ç‚¹: #{@lb_nodes.size} ä¸ª")

    # 0. é¦–å…ˆè¿›è¡Œæ‰€æœ‰èŠ‚ç‚¹çš„åˆå§‹åŒ–å’Œæ€§èƒ½ä¼˜åŒ–
    initialize_all_nodes

    # 1. éƒ¨ç½²è´Ÿè½½å‡è¡¡èŠ‚ç‚¹
    deploy_lb_nodes

    # 2. éƒ¨ç½²ç¬¬ä¸€ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹
    deploy_first_server

    # 3. éƒ¨ç½²å…¶ä»–æœåŠ¡å™¨èŠ‚ç‚¹
    deploy_additional_servers

    # 4. éƒ¨ç½²å·¥ä½œèŠ‚ç‚¹
    deploy_agent_nodes

    # 5. é…ç½® Ingress Controller ä¸º DaemonSet æ¨¡å¼
    configure_ingress_daemonset

    log('ğŸ‰ RKE2 é›†ç¾¤éƒ¨ç½²å®Œæˆ!')
  end

  def log(msg)
    puts msg
    @logger.info(msg)
  end

  def initialize_all_nodes
    log('ğŸ”§ å¼€å§‹æ‰€æœ‰èŠ‚ç‚¹çš„åˆå§‹åŒ–å’Œæ€§èƒ½ä¼˜åŒ–...')

    all_nodes = @server_nodes + @agent_nodes + @lb_nodes
    log("éœ€è¦åˆå§‹åŒ–çš„èŠ‚ç‚¹æ€»æ•°: #{all_nodes.size}")

    all_nodes.each do |node|
      initialize_node(node)
    end

    log('âœ… æ‰€æœ‰èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ!')
  end

  def initialize_node(node)
    log("ğŸ”§ åˆå§‹åŒ–èŠ‚ç‚¹ #{node['name']} (#{node['ip']})")

    begin
      Net::SSH.start(node['ip'], node['ssh_user'], timeout: 30) do |ssh|
        log("ğŸ“¤ ä¸Šä¼ åˆå§‹åŒ–è„šæœ¬åˆ° #{node['name']}...")

        # ç”Ÿæˆåˆå§‹åŒ–è„šæœ¬
        init_script = generate_init_script(node)
        ssh.scp.upload!(StringIO.new(init_script), '/tmp/node_init.sh')
        ssh.exec!('chmod +x /tmp/node_init.sh')

        log("âš™ï¸  åœ¨ #{node['name']} ä¸Šæ‰§è¡Œåˆå§‹åŒ–...")
        output = ssh.exec!('sudo bash /tmp/node_init.sh 2>&1')
        log("ğŸ“‹ #{node['name']} åˆå§‹åŒ–è¾“å‡º:")
        log(output)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        ssh.exec!('rm -f /tmp/node_init.sh')

        log("âœ… #{node['name']} åˆå§‹åŒ–å®Œæˆ")
      end
    rescue StandardError => e
      log("âŒ #{node['name']} åˆå§‹åŒ–å¤±è´¥: #{e.message}")
      @logger.error("#{node['name']} initialization failed: #{e.message}")
    end
  end

  def generate_init_script(node)
    <<~SH
            #!/bin/bash
            set -e
            echo "ğŸ”§ å¼€å§‹åˆå§‹åŒ–èŠ‚ç‚¹ #{node['name']}..."

            # æ›´æ–°ç³»ç»Ÿä¿¡æ¯
            echo "ğŸ“Š ç³»ç»Ÿä¿¡æ¯:"
            echo "  ä¸»æœºå: $(hostname)"
            echo "  ç³»ç»Ÿç‰ˆæœ¬: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'=' -f2 | tr -d '\"')"
            echo "  å†…æ ¸ç‰ˆæœ¬: $(uname -r)"
            echo "  CPU æ ¸å¿ƒæ•°: $(nproc)"
            echo "  å†…å­˜å¤§å°: $(free -h | grep Mem | awk '{print $2}')"
            echo "  ç£ç›˜ç©ºé—´: $(df -h / | tail -1 | awk '{print $4}' | sed 's/G/ GB/')"

            # 1. ç³»ç»Ÿæ—¶é—´åŒæ­¥
            echo "ğŸ• é…ç½®æ—¶é—´åŒæ­¥..."

            # æ£€æµ‹å¹¶é…ç½®æ—¶é—´åŒæ­¥æœåŠ¡
            if systemctl list-unit-files | grep -q "^chrony\.service"; then
              # ä½¿ç”¨ chrony.service è€Œä¸æ˜¯ chronyd.service
              systemctl enable chrony
              systemctl restart chrony
              echo "  âœ… chrony æ—¶é—´åŒæ­¥å·²å¯ç”¨"
            elif systemctl list-unit-files | grep -q "^chronyd\.service"; then
              # å¯¹äºä¸€äº›ç³»ç»Ÿï¼Œchronyd å¯èƒ½æ˜¯ä¸»æœåŠ¡å
              systemctl enable chronyd 2>/dev/null || systemctl enable chrony
              systemctl restart chronyd 2>/dev/null || systemctl restart chrony
              echo "  âœ… chronyd/chrony æ—¶é—´åŒæ­¥å·²å¯ç”¨"
            elif command -v ntpd >/dev/null 2>&1; then
              systemctl enable ntp 2>/dev/null || systemctl enable ntpd
              systemctl restart ntp 2>/dev/null || systemctl restart ntpd
              echo "  âœ… ntp æ—¶é—´åŒæ­¥å·²å¯ç”¨"
            else
              # å°è¯•å®‰è£…æ—¶é—´åŒæ­¥æœåŠ¡
              echo "  ğŸ“¦ å®‰è£…æ—¶é—´åŒæ­¥æœåŠ¡..."
              if command -v apt-get >/dev/null 2>&1; then
                apt-get update -qq >/dev/null 2>&1
                apt-get install -y chrony >/dev/null 2>&1
                systemctl enable chrony >/dev/null 2>&1
                systemctl start chrony >/dev/null 2>&1
                echo "  âœ… chrony å·²å®‰è£…å¹¶å¯ç”¨"
              elif command -v yum >/dev/null 2>&1; then
                yum install -y chrony >/dev/null 2>&1
                systemctl enable chronyd >/dev/null 2>&1
                systemctl start chronyd >/dev/null 2>&1
                echo "  âœ… chrony å·²å®‰è£…å¹¶å¯ç”¨"
              elif command -v dnf >/dev/null 2>&1; then
                dnf install -y chrony >/dev/null 2>&1
                systemctl enable chronyd >/dev/null 2>&1
                systemctl start chronyd >/dev/null 2>&1
                echo "  âœ… chrony å·²å®‰è£…å¹¶å¯ç”¨"
              else
                echo "  âš ï¸  æ— æ³•å®‰è£…æ—¶é—´åŒæ­¥æœåŠ¡ï¼Œè¯·æ‰‹åŠ¨é…ç½®"
              fi
            fi

            # éªŒè¯æ—¶é—´åŒæ­¥çŠ¶æ€
            if systemctl is-active chrony >/dev/null 2>&1; then
              echo "  ğŸ“Š chrony çŠ¶æ€: $(systemctl is-active chrony)"
            elif systemctl is-active chronyd >/dev/null 2>&1; then
              echo "  ğŸ“Š chronyd çŠ¶æ€: $(systemctl is-active chronyd)"
            elif systemctl is-active ntp >/dev/null 2>&1; then
              echo "  ğŸ“Š ntp çŠ¶æ€: $(systemctl is-active ntp)"
            elif systemctl is-active ntpd >/dev/null 2>&1; then
              echo "  ğŸ“Š ntpd çŠ¶æ€: $(systemctl is-active ntpd)"
            fi

            # 2. ç¦ç”¨ swap
            echo "ğŸ’¾ ç¦ç”¨ swap..."
            swapoff -a
            sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab
            echo "  âœ… swap å·²ç¦ç”¨"

            # 3. å†…æ ¸æ¨¡å—åŠ è½½
            echo "ğŸ”§ é…ç½®å†…æ ¸æ¨¡å—..."
            cat > /etc/modules-load.d/k8s.conf << 'EOF'
      overlay
      br_netfilter
      ip_vs
      ip_vs_rr
      ip_vs_wrr
      ip_vs_sh
      nf_conntrack
      EOF

            # åŠ è½½æ¨¡å—
            modprobe overlay 2>/dev/null || true
            modprobe br_netfilter 2>/dev/null || true
            modprobe ip_vs 2>/dev/null || true
            modprobe ip_vs_rr 2>/dev/null || true
            modprobe ip_vs_wrr 2>/dev/null || true
            modprobe ip_vs_sh 2>/dev/null || true
            modprobe nf_conntrack 2>/dev/null || true
            echo "  âœ… å†…æ ¸æ¨¡å—å·²åŠ è½½"

            # 4. ç³»ç»Ÿå‚æ•°ä¼˜åŒ–
            echo "âš¡ é…ç½®ç³»ç»Ÿå‚æ•°ä¼˜åŒ–..."
            cat > /etc/sysctl.d/99-k8s.conf << 'EOF'
      # ç½‘ç»œä¼˜åŒ–
      net.bridge.bridge-nf-call-iptables = 1
      net.bridge.bridge-nf-call-ip6tables = 1
      net.ipv4.ip_forward = 1
      net.ipv4.conf.all.forwarding = 1
      net.ipv6.conf.all.forwarding = 1

      # è¿æ¥è·Ÿè¸ªä¼˜åŒ–
      net.netfilter.nf_conntrack_max = 1000000
      net.netfilter.nf_conntrack_tcp_timeout_established = 86400

      # TCP ä¼˜åŒ–
      net.core.somaxconn = 32768
      net.core.netdev_max_backlog = 16384
      net.core.rmem_default = 262144
      net.core.rmem_max = 16777216
      net.core.wmem_default = 262144
      net.core.wmem_max = 16777216
      net.ipv4.tcp_rmem = 4096 65536 16777216
      net.ipv4.tcp_wmem = 4096 65536 16777216
      net.ipv4.tcp_max_syn_backlog = 8192
      net.ipv4.tcp_slow_start_after_idle = 0

      # å†…å­˜å’Œè¿›ç¨‹ä¼˜åŒ–
      vm.swappiness = 0
      vm.overcommit_memory = 1
      vm.panic_on_oom = 0
      vm.max_map_count = 262144
      kernel.panic = 10
      kernel.panic_on_oops = 1
      kernel.pid_max = 4194304

      # æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
      fs.file-max = 2097152
      fs.inotify.max_user_instances = 8192
      fs.inotify.max_user_watches = 524288
      fs.may_detach_mounts = 1

      # å®‰å…¨ä¼˜åŒ–
      kernel.dmesg_restrict = 1
      net.ipv4.conf.all.send_redirects = 0
      net.ipv4.conf.default.send_redirects = 0
      net.ipv4.conf.all.accept_redirects = 0
      net.ipv4.conf.default.accept_redirects = 0
      net.ipv4.conf.all.accept_source_route = 0
      net.ipv4.conf.default.accept_source_route = 0
      EOF

            # åº”ç”¨ç³»ç»Ÿå‚æ•°
            sysctl --system >/dev/null 2>&1
            echo "  âœ… ç³»ç»Ÿå‚æ•°ä¼˜åŒ–å·²åº”ç”¨"

            # 5. ç³»ç»Ÿé™åˆ¶ä¼˜åŒ–
            echo "ğŸ“ˆ é…ç½®ç³»ç»Ÿé™åˆ¶..."
            cat > /etc/security/limits.d/99-k8s.conf << 'EOF'
      * soft nofile 1048576
      * hard nofile 1048576
      * soft nproc 1048576
      * hard nproc 1048576
      * soft core unlimited
      * hard core unlimited
      * soft memlock unlimited
      * hard memlock unlimited
      root soft nofile 1048576
      root hard nofile 1048576
      root soft nproc 1048576
      root hard nproc 1048576
      EOF
            echo "  âœ… ç³»ç»Ÿé™åˆ¶å·²ä¼˜åŒ–"

            # 6. é˜²ç«å¢™é…ç½®
            echo "ğŸ”¥ é…ç½®é˜²ç«å¢™..."
            if systemctl is-active firewalld >/dev/null 2>&1; then
              echo "  ç¦ç”¨ firewalld (ä½¿ç”¨ iptables)..."
              systemctl stop firewalld
              systemctl disable firewalld
            fi

            if systemctl is-active ufw >/dev/null 2>&1; then
              echo "  ç¦ç”¨ ufw (ä½¿ç”¨ iptables)..."
              systemctl stop ufw
              systemctl disable ufw
            fi
            echo "  âœ… é˜²ç«å¢™å·²é…ç½®"

            # 7. å®‰è£…å¿…è¦çš„ç³»ç»Ÿå·¥å…·
            echo "ğŸ“¦ å®‰è£…ç³»ç»Ÿå·¥å…·..."
            if command -v apt-get >/dev/null 2>&1; then
              export DEBIAN_FRONTEND=noninteractive
              apt-get update -qq
              apt-get install -y \\
                curl wget git vim htop iotop nethogs \\
                net-tools dnsutils ipset conntrack \\
                socat jq unzip tar gzip \\
                ca-certificates gnupg lsb-release \\
                apt-transport-https software-properties-common \\
                >/dev/null 2>&1
            elif command -v yum >/dev/null 2>&1; then
              yum install -y \\
                curl wget git vim htop iotop nethogs \\
                net-tools bind-utils ipset conntrack-tools \\
                socat jq unzip tar gzip \\
                ca-certificates gnupg \\
                yum-utils device-mapper-persistent-data lvm2 \\
                >/dev/null 2>&1
            fi
            echo "  âœ… ç³»ç»Ÿå·¥å…·å®‰è£…å®Œæˆ"

            # 8. ç£ç›˜æ€§èƒ½ä¼˜åŒ–
            echo "ğŸ’¿ ä¼˜åŒ–ç£ç›˜æ€§èƒ½..."
            # è®¾ç½®ç£ç›˜è°ƒåº¦å™¨ä¸º deadline æˆ– noop
            for disk in $(lsblk -d -n -o NAME | grep -E '^(sd|vd|nvme)'); do
              if [ -f "/sys/block/$disk/queue/scheduler" ]; then
                if grep -q "\\[mq-deadline\\]" "/sys/block/$disk/queue/scheduler"; then
                  echo "  ç£ç›˜ $disk å·²ä½¿ç”¨ mq-deadline è°ƒåº¦å™¨"
                elif grep -q "deadline" "/sys/block/$disk/queue/scheduler"; then
                  echo deadline > "/sys/block/$disk/queue/scheduler" 2>/dev/null || true
                  echo "  ç£ç›˜ $disk è®¾ç½®ä¸º deadline è°ƒåº¦å™¨"
                elif grep -q "noop" "/sys/block/$disk/queue/scheduler"; then
                  echo noop > "/sys/block/$disk/queue/scheduler" 2>/dev/null || true
                  echo "  ç£ç›˜ $disk è®¾ç½®ä¸º noop è°ƒåº¦å™¨"
                fi
              fi
            done
            echo "  âœ… ç£ç›˜è°ƒåº¦å™¨å·²ä¼˜åŒ–"

            # 9. è®¾ç½®ä¸»æœºå
            echo "ğŸ·ï¸  è®¾ç½®ä¸»æœºå..."
            if [ "$(hostname)" != "#{node['name']}" ]; then
              hostnamectl set-hostname #{node['name']} 2>/dev/null || hostname #{node['name']}
              echo "  âœ… ä¸»æœºåå·²è®¾ç½®ä¸º #{node['name']}"
            else
              echo "  âœ… ä¸»æœºåå·²æ­£ç¡®è®¾ç½®"
            fi

            # 10. é…ç½® DNS è§£æä¼˜åŒ–
            echo "ğŸŒ ä¼˜åŒ– DNS é…ç½®..."
            # å¤‡ä»½åŸå§‹ resolv.conf
            if [ ! -f /etc/resolv.conf.backup ]; then
              cp /etc/resolv.conf /etc/resolv.conf.backup
            fi

            # æ·»åŠ é«˜æ€§èƒ½ DNS æœåŠ¡å™¨
            cat > /etc/resolv.conf.new << 'EOF'
      # Optimized DNS configuration for Kubernetes
      nameserver 8.8.8.8
      nameserver 8.8.4.4
      nameserver 1.1.1.1
      nameserver 1.0.0.1
      options timeout:2 attempts:3 rotate single-request-reopen
      EOF

            # å¦‚æœåŸæ¥æœ‰è‡ªå®šä¹‰ DNSï¼Œä¿ç•™å®ƒä»¬
            if grep -v "^#" /etc/resolv.conf.backup | grep -q "nameserver"; then
              grep "nameserver" /etc/resolv.conf.backup | head -2 > /tmp/custom_dns
              cat /tmp/custom_dns /etc/resolv.conf.new > /etc/resolv.conf.tmp
              mv /etc/resolv.conf.tmp /etc/resolv.conf
              rm -f /tmp/custom_dns
            else
              mv /etc/resolv.conf.new /etc/resolv.conf
            fi
            echo "  âœ… DNS é…ç½®å·²ä¼˜åŒ–"

            # 11. å†…å­˜ä¼˜åŒ–
            echo "ğŸ§  é…ç½®å†…å­˜ä¼˜åŒ–..."
            # é…ç½®å†…å­˜å›æ”¶ç­–ç•¥
            echo 1 > /proc/sys/vm/drop_caches 2>/dev/null || true

            # å¦‚æœæ˜¯è™šæ‹Ÿæœºï¼Œç¦ç”¨é€æ˜å¤§é¡µ
            if [ -f /sys/kernel/mm/transparent_hugepage/enabled ]; then
              echo never > /sys/kernel/mm/transparent_hugepage/enabled 2>/dev/null || true
              echo never > /sys/kernel/mm/transparent_hugepage/defrag 2>/dev/null || true
              echo "  âœ… é€æ˜å¤§é¡µå·²ç¦ç”¨"
            fi

            # é…ç½®å¼€æœºè‡ªåŠ¨ç¦ç”¨é€æ˜å¤§é¡µ
            cat > /etc/systemd/system/disable-thp.service << 'EOF'
      [Unit]
      Description=Disable Transparent Huge Pages (THP)
      DefaultDependencies=no
      After=sysinit.target local-fs.target
      Before=basic.target

      [Service]
      Type=oneshot
      ExecStart=/bin/sh -c 'echo never | tee /sys/kernel/mm/transparent_hugepage/enabled /sys/kernel/mm/transparent_hugepage/defrag'

      [Install]
      WantedBy=basic.target
      EOF
            systemctl enable disable-thp.service >/dev/null 2>&1 || true
            echo "  âœ… å†…å­˜ä¼˜åŒ–å·²é…ç½®"

            # 12. ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
            echo "ğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥..."
            echo "  CPU ä½¿ç”¨ç‡: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)%"
            echo "  å†…å­˜ä½¿ç”¨ç‡: $(free | grep Mem | awk '{printf("%.1f%%\\n", $3/$2 * 100.0)}')"
            echo "  ç£ç›˜ä½¿ç”¨ç‡: $(df -h / | tail -1 | awk '{print $5}')"
            echo "  ç³»ç»Ÿè´Ÿè½½: $(uptime | awk -F'load average:' '{print $2}')"
            echo "  æ‰“å¼€æ–‡ä»¶æ•°é™åˆ¶: $(ulimit -n)"
            echo "  è¿›ç¨‹æ•°é™åˆ¶: $(ulimit -u)"

            # 13. é‡å¯å¿…è¦çš„æœåŠ¡
            echo "ğŸ”„ é‡å¯ç³»ç»ŸæœåŠ¡..."
            systemctl daemon-reload

            # é‡å¯ç½‘ç»œç›¸å…³æœåŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if systemctl is-enabled systemd-networkd >/dev/null 2>&1; then
              systemctl restart systemd-networkd
            fi

            if systemctl is-enabled NetworkManager >/dev/null 2>&1; then
              systemctl restart NetworkManager
            fi
            echo "  âœ… ç³»ç»ŸæœåŠ¡å·²é‡å¯"

            echo ""
            echo "ğŸ‰ èŠ‚ç‚¹ #{node['name']} åˆå§‹åŒ–å®Œæˆï¼"
            echo "ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–æ‘˜è¦:"
            echo "  - âœ… æ—¶é—´åŒæ­¥å·²é…ç½®"
            echo "  - âœ… Swap å·²ç¦ç”¨"
            echo "  - âœ… å†…æ ¸æ¨¡å—å·²åŠ è½½"
            echo "  - âœ… ç³»ç»Ÿå‚æ•°å·²ä¼˜åŒ–"
            echo "  - âœ… ç³»ç»Ÿé™åˆ¶å·²è°ƒæ•´"
            echo "  - âœ… é˜²ç«å¢™å·²é…ç½®"
            echo "  - âœ… ç³»ç»Ÿå·¥å…·å·²å®‰è£…"
            echo "  - âœ… ç£ç›˜æ€§èƒ½å·²ä¼˜åŒ–"
            echo "  - âœ… ä¸»æœºåå·²è®¾ç½®"
            echo "  - âœ… DNS å·²ä¼˜åŒ–"
            echo "  - âœ… å†…å­˜ä¼˜åŒ–å·²å¯ç”¨"
            echo ""
            echo "ğŸ’¡ å»ºè®®: åœ¨ç»§ç»­éƒ¨ç½²å‰é‡å¯èŠ‚ç‚¹ä»¥ç¡®ä¿æ‰€æœ‰ä¼˜åŒ–ç”Ÿæ•ˆ"
            echo "   é‡å¯å‘½ä»¤: sudo reboot"
            echo ""
    SH
  end

  def deploy_lb_nodes
    return if @lb_nodes.empty?

    log('ğŸ“‹ éƒ¨ç½²è´Ÿè½½å‡è¡¡èŠ‚ç‚¹...')
    @lb_nodes.each do |node|
      log("ğŸ”§ é…ç½®è´Ÿè½½å‡è¡¡å™¨ #{node['name']} (#{node['ip']})")
      write_nginx_config(node)
      write_lb_install_script(node)
      deploy_to_node(node)
    end
  end

  def deploy_first_server
    return if @server_nodes.empty?

    first_server = @server_nodes.first
    log("ğŸ”§ éƒ¨ç½²ç¬¬ä¸€ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ #{first_server['name']}")
    write_config_file(first_server, true)
    write_install_script(first_server)
    deploy_to_node(first_server)

    # ç­‰å¾…ç¬¬ä¸€ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹å¯åŠ¨
    wait_for_server_ready(first_server)
  end

  def deploy_additional_servers
    additional_servers = @server_nodes[1..] || []
    return if additional_servers.empty?

    log('ğŸ”§ éƒ¨ç½²å…¶ä»–æœåŠ¡å™¨èŠ‚ç‚¹...')
    additional_servers.each do |node|
      log("ğŸ”§ é…ç½®æœåŠ¡å™¨èŠ‚ç‚¹ #{node['name']}")
      write_config_file(node, false)
      write_install_script(node)
      deploy_to_node(node)
    end
  end

  def deploy_agent_nodes
    return if @agent_nodes.empty?

    log('ğŸ”§ éƒ¨ç½²å·¥ä½œèŠ‚ç‚¹...')
    @agent_nodes.each do |node|
      log("ğŸ”§ é…ç½®å·¥ä½œèŠ‚ç‚¹ #{node['name']}")
      write_config_file(node, false)
      write_install_script(node)
      deploy_to_node(node)
    end
  end

  def write_nginx_config(node)
    # è·å–æ‰€æœ‰æœåŠ¡å™¨èŠ‚ç‚¹çš„IPåœ°å€
    server_ips = @server_nodes.map { |n| n['ip'] }

    haproxy_config = <<~HAPROXY
      global
        daemon
        log stdout local0
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin
        stats timeout 30s
        user haproxy
        group haproxy

      defaults
        mode tcp
        log global
        option tcplog
        option dontlognull
        option log-health-checks
        timeout connect 5000ms
        timeout client 50000ms
        timeout server 50000ms

      # Kubernetes API Server
      frontend kubernetes-api
        bind *:6443
        mode tcp
        default_backend kubernetes-api-backend

      backend kubernetes-api-backend
        mode tcp
        balance roundrobin
        option tcp-check
        #{server_ips.map { |ip| "server master-#{ip.gsub('.', '-')} #{ip}:6443 check" }.join("\n  ")}

      # RKE2 Registration Server
      frontend rke2-registration
        bind *:9345
        mode tcp
        default_backend rke2-registration-backend

      backend rke2-registration-backend
        mode tcp
        balance roundrobin
        option tcp-check
        #{server_ips.map { |ip| "server master-#{ip.gsub('.', '-')} #{ip}:9345 check" }.join("\n  ")}

      # Stats interface
      frontend stats
        bind *:8404
        mode http
        stats enable
        stats uri /stats
        stats refresh 30s
        stats admin if TRUE
    HAPROXY

    dir = "output/#{node['name']}"
    FileUtils.mkdir_p(dir)
    File.write("#{dir}/haproxy.cfg", haproxy_config)
  end

  def write_lb_install_script(node)
    script = <<~SH
      #!/bin/bash
      set -e
      echo "ğŸš€ Installing HAProxy Load Balancer on #{node['name']}"

      # å®‰è£… HAProxy
      if command -v apt-get >/dev/null 2>&1; then
        apt-get update
        apt-get install -y haproxy
      elif command -v yum >/dev/null 2>&1; then
        yum install -y haproxy
      else
        echo "âŒ ä¸æ”¯æŒçš„åŒ…ç®¡ç†å™¨"
        exit 1
      fi

      # å¤‡ä»½åŸå§‹é…ç½®
      cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.backup

      # å¤åˆ¶æˆ‘ä»¬çš„é…ç½®æ–‡ä»¶
      cp /tmp/haproxy.cfg /etc/haproxy/haproxy.cfg

      # æµ‹è¯•é…ç½®
      haproxy -f /etc/haproxy/haproxy.cfg -c

      # å¯ç”¨å¹¶å¯åŠ¨ HAProxy
      systemctl enable haproxy
      systemctl restart haproxy

      # æ£€æŸ¥ HAProxy çŠ¶æ€
      systemctl status haproxy --no-pager

      # æ˜¾ç¤ºç›‘å¬ç«¯å£
      echo "ğŸ” æ£€æŸ¥ç›‘å¬ç«¯å£:"
      ss -tlnp | grep -E ':6443|:9345|:8404'

      echo "âœ… HAProxy è´Ÿè½½å‡è¡¡å™¨é…ç½®å®Œæˆ"
      echo "ğŸ“Š ç»Ÿè®¡é¡µé¢: http://#{node['ip']}:8404/stats"
    SH

    File.write("output/#{node['name']}/install.sh", script)
    FileUtils.chmod('+x', "output/#{node['name']}/install.sh")
  end

  def write_config_file(node, is_first_server = false)
    content = case node['role']
              when 'server'
                if is_first_server
                  <<~YAML
                    token: #{@token}
                    node-name: #{node['name']}
                    bind-address: 0.0.0.0
                    advertise-address: #{node['ip']}
                    tls-san:
                      - "0.0.0.0"
                      - "#{@lb_ip}"
                      - "#{node['ip']}"
                    cni: canal
                    write-kubeconfig-mode: "0644"
                    cluster-init: true
                  YAML
                else
                  <<~YAML
                    server: https://#{@lb_ip}:9345
                    token: #{@token}
                    node-name: #{node['name']}
                    bind-address: 0.0.0.0
                    advertise-address: #{node['ip']}
                    tls-san:
                      - "0.0.0.0"
                      - "#{@lb_ip}"
                      - "#{node['ip']}"
                    cni: canal
                    write-kubeconfig-mode: "0644"
                  YAML
                end
              when 'agent'
                <<~YAML
                  server: https://#{@lb_ip}:9345
                  token: #{@token}
                  node-name: #{node['name']}
                YAML
              end

    return unless content

    dir = "output/#{node['name']}"
    FileUtils.mkdir_p(dir)
    File.write("#{dir}/config.yaml", content)
  end

  def write_install_script(node)
    role = node['role']
    service = role == 'server' ? 'rke2-server' : 'rke2-agent'

    script = <<~SH
      #!/bin/bash
      set -e
      echo "ğŸš€ Installing RKE2 (#{role}) on #{node['name']}"

      # ä¸‹è½½å¹¶å®‰è£… RKE2
      curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE=#{role} sh -

      # åˆ›å»ºé…ç½®ç›®å½•
      mkdir -p /etc/rancher/rke2

      # å¤åˆ¶é…ç½®æ–‡ä»¶
      cp /tmp/config.yaml /etc/rancher/rke2/config.yaml

      # è®¾ç½®æ­£ç¡®çš„æƒé™
      chmod 600 /etc/rancher/rke2/config.yaml

      # å¯ç”¨æœåŠ¡
      systemctl enable #{service}

      # å¯åŠ¨æœåŠ¡
      systemctl restart #{service}

      echo "âœ… RKE2 #{role} å®‰è£…å®Œæˆ"

      # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
      systemctl status #{service} --no-pager
    SH

    # å¦‚æœæ˜¯ server èŠ‚ç‚¹ï¼Œæ·»åŠ  kubectl é…ç½®
    if role == 'server'
      script += <<~SH

                echo "ğŸ”§ é…ç½® kubectl for root ç”¨æˆ·..."

                # ç­‰å¾… kubeconfig æ–‡ä»¶ç”Ÿæˆ (æœ€å¤šç­‰å¾… 60 ç§’)
                echo "â³ ç­‰å¾… kubeconfig æ–‡ä»¶ç”Ÿæˆ..."
                for i in {1..12}; do
                  if [ -f /etc/rancher/rke2/rke2.yaml ]; then
                    break
                  fi
                  echo "  ç­‰å¾…ä¸­... ($i/12)"
                  sleep 5
                done

                if [ ! -f /etc/rancher/rke2/rke2.yaml ]; then
                  echo "âŒ kubeconfig æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¨åæ‰‹åŠ¨é…ç½®"
                  exit 1
                fi

                # åˆ›å»º kubectl è½¯é“¾æ¥åˆ°ç³»ç»Ÿ PATH
                echo "ğŸ”— åˆ›å»º kubectl è½¯é“¾æ¥..."
                ln -sf /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl
                chmod +x /usr/local/bin/kubectl

                # ä¸º root ç”¨æˆ·è®¾ç½® kubeconfig
                echo "ğŸ“ ä¸º root ç”¨æˆ·é…ç½® kubeconfig..."
                mkdir -p /root/.kube
                cp /etc/rancher/rke2/rke2.yaml /root/.kube/config
                chmod 600 /root/.kube/config
                chown root:root /root/.kube/config

                # è®¾ç½®ç¯å¢ƒå˜é‡åˆ° root çš„ bashrc
                echo "ğŸ”§ é…ç½®ç¯å¢ƒå˜é‡..."
                if ! grep -q "KUBECONFIG" /root/.bashrc; then
                  echo "# RKE2 kubectl configuration" >> /root/.bashrc
                  echo "export KUBECONFIG=/root/.kube/config" >> /root/.bashrc
                  echo "export PATH=/var/lib/rancher/rke2/bin:$PATH" >> /root/.bashrc
                  echo "alias k=kubectl" >> /root/.bashrc
                fi

                # è®¾ç½®ç¯å¢ƒå˜é‡åˆ° root çš„ profile
                if ! grep -q "KUBECONFIG" /root/.profile; then
                  echo "# RKE2 kubectl configuration" >> /root/.profile
                  echo "export KUBECONFIG=/root/.kube/config" >> /root/.profile
                  echo "export PATH=/var/lib/rancher/rke2/bin:$PATH" >> /root/.profile
                fi

                # æµ‹è¯• kubectl é…ç½®
                echo "ğŸ§ª æµ‹è¯• kubectl é…ç½®..."
                export KUBECONFIG=/root/.kube/config
                export PATH=/var/lib/rancher/rke2/bin:$PATH

                # ç­‰å¾… API æœåŠ¡å™¨å°±ç»ª
                echo "â³ ç­‰å¾… Kubernetes API æœåŠ¡å™¨å°±ç»ª..."
                for i in {1..24}; do
                  if kubectl cluster-info >/dev/null 2>&1; then
                    echo "âœ… API æœåŠ¡å™¨å·²å°±ç»ª"
                    break
                  fi
                  echo "  ç­‰å¾… API æœåŠ¡å™¨... ($i/24)"
                  sleep 5
                done

                # éªŒè¯ kubectl åŠŸèƒ½
                echo "ğŸ” éªŒè¯ kubectl åŠŸèƒ½..."
                if kubectl get nodes >/dev/null 2>&1; then
                  echo "âœ… kubectl é…ç½®æˆåŠŸï¼"
                  echo "ğŸ“Š å½“å‰é›†ç¾¤èŠ‚ç‚¹:"
                  kubectl get nodes
                else
                  echo "âš ï¸  kubectl é…ç½®å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´ç”Ÿæ•ˆ"
                fi

                echo ""
                echo "ğŸ‰ kubectl é…ç½®å®Œæˆï¼"
                echo "ğŸ’¡ æç¤º: é‡æ–°ç™»å½• root ç”¨æˆ·åï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:"
                echo "   kubectl get nodes"
                echo "   k get pods --all-namespaces"
                echo ""

                # å®‰è£… k9s
                echo "ğŸ“¦ å®‰è£… k9s..."
                K9S_VERSION=$(curl -s https://api.github.com/repos/derailed/k9s/releases/latest | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\\1/')
                echo "  ä¸‹è½½ k9s $K9S_VERSION..."

                # æ£€æµ‹ç³»ç»Ÿæ¶æ„
                ARCH=$(uname -m)
                case $ARCH in
                  x86_64) K9S_ARCH="amd64" ;;
                  aarch64) K9S_ARCH="arm64" ;;
                  *) K9S_ARCH="amd64" ;;
                esac

                curl -sL "https://github.com/derailed/k9s/releases/download/$K9S_VERSION/k9s_Linux_$K9S_ARCH.tar.gz" -o /tmp/k9s.tar.gz
                tar -xzf /tmp/k9s.tar.gz -C /tmp
                mv /tmp/k9s /usr/local/bin/k9s
                chmod +x /usr/local/bin/k9s
                rm -f /tmp/k9s.tar.gz /tmp/LICENSE /tmp/README.md

                # éªŒè¯ k9s å®‰è£…
                if k9s version >/dev/null 2>&1; then
                  echo "  âœ… k9s å®‰è£…æˆåŠŸ: $(k9s version --short)"
                else
                  echo "  âš ï¸  k9s å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                fi

                # å®‰è£… helm
                echo "ğŸ“¦ å®‰è£… helm..."
                curl -fsSL -o /tmp/get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
                chmod 700 /tmp/get_helm.sh
                HELM_INSTALL_DIR="/usr/local/bin" /tmp/get_helm.sh --no-sudo >/dev/null 2>&1
                rm -f /tmp/get_helm.sh

                # éªŒè¯ helm å®‰è£…
                if helm version >/dev/null 2>&1; then
                  echo "  âœ… helm å®‰è£…æˆåŠŸ: $(helm version --short)"
                else
                  echo "  âš ï¸  helm å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                fi

                # åˆå§‹åŒ– helm
                echo "ğŸ”§ åˆå§‹åŒ– helm..."
                export KUBECONFIG=/root/.kube/config
                helm repo add stable https://charts.helm.sh/stable >/dev/null 2>&1 || true
                helm repo add bitnami https://charts.bitnami.com/bitnami >/dev/null 2>&1 || true
                helm repo update >/dev/null 2>&1 || true
                echo "  âœ… helm ä»“åº“åˆå§‹åŒ–å®Œæˆ"

                # åˆ›å»º k9s é…ç½®ç›®å½•
                echo "ğŸ”§ é…ç½® k9s..."
                mkdir -p /root/.config/k9s

                # åˆ›å»º k9s åŸºç¡€é…ç½®
                cat > /root/.config/k9s/config.yml << 'EOF'
        k9s:
          liveViewAutoRefresh: true
          refreshRate: 2
          maxConnRetry: 5
          readOnly: false
          noExitOnCtrlC: false
          ui:
            enableMouse: true
            headless: false
            logoless: false
            crumbsless: false
            reactive: false
            noIcons: false
          skipLatestRevCheck: false
          disablePodCounting: false
          shellPod:
            image: busybox:1.35.0
            namespace: default
            limits:
              cpu: 100m
              memory: 100Mi
          imageScanner:
            enable: false
          logger:
            tail: 100
            buffer: 5000
            sinceSeconds: -1
            textWrap: false
            showTime: false
        EOF

                echo ""
                echo "ğŸ‰ k9s å’Œ helm å®‰è£…å®Œæˆï¼"
                echo ""
                echo "ğŸ’¡ å¯ç”¨å·¥å…·ï¼š"
                echo "   kubectl get nodes          # Kubernetes å‘½ä»¤è¡Œå·¥å…·"
                echo "   k get pods --all-namespaces # kubectl åˆ«å"
                echo "   k9s                        # ç»ˆç«¯ UI é›†ç¾¤ç®¡ç†å·¥å…·"
                echo "   helm list                  # Kubernetes åŒ…ç®¡ç†å™¨"
                echo ""
                echo "ğŸš€ k9s ä½¿ç”¨æç¤ºï¼š"
                echo "   - æŒ‰ ':' è¿›å…¥å‘½ä»¤æ¨¡å¼"
                echo "   - è¾“å…¥èµ„æºåç§°å¿«é€Ÿè·³è½¬ (pods, svc, deploy ç­‰)"
                echo "   - æŒ‰ '?' æŸ¥çœ‹å¸®åŠ©"
                echo "   - æŒ‰ 'Ctrl+C' é€€å‡º"
                echo ""
      SH
    end

    File.write("output/#{node['name']}/install.sh", script)
    FileUtils.chmod('+x', "output/#{node['name']}/install.sh")
  end

  def wait_for_server_ready(node)
    log("â³ ç­‰å¾…æœåŠ¡å™¨èŠ‚ç‚¹ #{node['name']} å°±ç»ª...")

    max_attempts = 30
    attempt = 0

    while attempt < max_attempts
      begin
        Net::SSH.start(node['ip'], node['ssh_user'], timeout: 10) do |ssh|
          # æ£€æŸ¥æœåŠ¡çŠ¶æ€
          status = ssh.exec!('systemctl is-active rke2-server').strip
          if status == 'active'
            # è¿›ä¸€æ­¥æ£€æŸ¥æœåŠ¡æ˜¯å¦çœŸæ­£å°±ç»ª
            ready_status = check_cluster_readiness(ssh, node)
            if ready_status[:ready]
              log("âœ… æœåŠ¡å™¨èŠ‚ç‚¹ #{node['name']} å·²å®Œå…¨å°±ç»ª")
              return true
            else
              log("â³ æœåŠ¡è¿è¡Œä¸­ä½†ç»„ä»¶ä»åœ¨åˆå§‹åŒ–... #{ready_status[:status]}")
            end
          else
            log("â³ æœåŠ¡çŠ¶æ€: #{status}")
          end
        end
      rescue StandardError => e
        log("â³ å°è¯• #{attempt + 1}/#{max_attempts}: #{e.message}")
      end

      attempt += 1
      sleep(30)
    end

    log("âš ï¸  æœåŠ¡å™¨èŠ‚ç‚¹ #{node['name']} å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´å¯åŠ¨")
    false
  end

  # æ£€æŸ¥é›†ç¾¤å°±ç»ªçŠ¶æ€çš„æ–°æ–¹æ³•
  def check_cluster_readiness(ssh, _node)
    # æ£€æŸ¥ containerd è¿›ç¨‹æ˜¯å¦è¿è¡Œ
    containerd_running = ssh.exec!('pgrep -f "containerd.*rke2" >/dev/null 2>&1 && echo "running" || echo "not_running"').strip

    # æ£€æŸ¥ kubelet è¿›ç¨‹æ˜¯å¦è¿è¡Œ
    kubelet_running = ssh.exec!('pgrep -f "kubelet.*rke2" >/dev/null 2>&1 && echo "running" || echo "not_running"').strip

    # æ£€æŸ¥ kubectl æ˜¯å¦å¯ç”¨å¹¶èƒ½è®¿é—® API
    kubectl_check = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl get nodes 2>/dev/null | wc -l').strip.to_i

    # æ£€æŸ¥ etcd æ˜¯å¦å¥åº·
    etcd_check = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl get nodes --selector node-role.kubernetes.io/etcd 2>/dev/null | grep -c Ready || echo 0').strip.to_i

    # æ£€æŸ¥ API æœåŠ¡å™¨æ˜¯å¦å“åº”
    api_server_check = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && timeout 5 /var/lib/rancher/rke2/bin/kubectl cluster-info >/dev/null 2>&1 && echo "responding" || echo "not_responding"').strip

    if containerd_running == 'running' && kubelet_running == 'running' && kubectl_check > 1 && etcd_check.positive? && api_server_check == 'responding'
      return { ready: true, status: 'All components operational' }
    end

    status_msg = "containerd:#{containerd_running}, kubelet:#{kubelet_running}, kubectl_nodes:#{kubectl_check}, etcd_ready:#{etcd_check}, api_server:#{api_server_check}"
    { ready: false, status: status_msg }
  rescue StandardError => e
    { ready: false, status: "Check failed: #{e.message}" }
  end

  # æ–°çš„è¯Šæ–­æ–¹æ³•
  def diagnose_cluster_status
    log('ğŸ” è¯Šæ–­é›†ç¾¤çŠ¶æ€...')

    @server_nodes.each do |node|
      log("\nğŸ“Š æ£€æŸ¥èŠ‚ç‚¹: #{node['name']} (#{node['ip']})")

      begin
        Net::SSH.start(node['ip'], node['ssh_user'], timeout: 15) do |ssh|
          # RKE2 æœåŠ¡çŠ¶æ€
          log('ğŸ”§ RKE2 æœåŠ¡çŠ¶æ€:')
          rke2_status = ssh.exec!("systemctl is-active rke2-server 2>/dev/null || echo 'not-found'").strip
          rke2_state = ssh.exec!("systemctl is-enabled rke2-server 2>/dev/null || echo 'not-found'").strip
          log("  rke2-server: #{rke2_status} (#{rke2_state})")

          # æ£€æŸ¥å…³é”®è¿›ç¨‹çŠ¶æ€ï¼ˆRKE2 ä¸­ containerd å’Œ kubelet æ˜¯å­è¿›ç¨‹ï¼‰
          log("\nğŸ”„ å…³é”®è¿›ç¨‹çŠ¶æ€:")
          containerd_running = ssh.exec!('pgrep -f "containerd.*rke2" >/dev/null && echo "running" || echo "not_running"').strip
          kubelet_running = ssh.exec!('pgrep -f "kubelet.*rke2" >/dev/null && echo "running" || echo "not_running"').strip
          etcd_running = ssh.exec!('pgrep -f "etcd.*rke2" >/dev/null && echo "running" || echo "not_running"').strip

          log("  containerd: #{containerd_running}")
          log("  kubelet: #{kubelet_running}")
          log("  etcd: #{etcd_running}")

          # æ£€æŸ¥è¿›ç¨‹è¯¦æƒ…
          log("\nğŸ” è¿›ç¨‹è¯¦æƒ…:")
          process_count = ssh.exec!('ps aux | grep -E "(rke2|containerd|kubelet|etcd)" | grep -v grep | wc -l').strip
          log("  RKE2 ç›¸å…³è¿›ç¨‹æ€»æ•°: #{process_count}")

          # æ£€æŸ¥æœ€è¿‘çš„ journal æ—¥å¿—
          log("\nğŸ“‹ æœ€è¿‘çš„ RKE2 æ—¥å¿— (æœ€å5è¡Œ):")
          recent_logs = ssh.exec!('journalctl -u rke2-server --no-pager -n 5 --since "2 minutes ago" 2>/dev/null || echo "æ— æ³•è·å–æ—¥å¿—"')
          log(recent_logs)

          # æ£€æŸ¥ç½‘ç»œå’Œç«¯å£
          log("\nğŸŒ ç½‘ç»œçŠ¶æ€:")
          api_port = ssh.exec!('ss -tlnp | grep ":6443" | wc -l').strip
          reg_port = ssh.exec!('ss -tlnp | grep ":9345" | wc -l').strip
          kubelet_port = ssh.exec!('ss -tlnp | grep ":10250" | wc -l').strip

          log("  API æœåŠ¡å™¨ç«¯å£ (6443): #{api_port > '0' ? 'âœ… ç›‘å¬ä¸­' : 'âŒ æœªç›‘å¬'}")
          log("  æ³¨å†ŒæœåŠ¡ç«¯å£ (9345): #{reg_port > '0' ? 'âœ… ç›‘å¬ä¸­' : 'âŒ æœªç›‘å¬'}")
          log("  Kubelet ç«¯å£ (10250): #{kubelet_port > '0' ? 'âœ… ç›‘å¬ä¸­' : 'âŒ æœªç›‘å¬'}")

          # æ£€æŸ¥é›†ç¾¤å°±ç»ªçŠ¶æ€
          log("\nğŸ¯ é›†ç¾¤å°±ç»ªæ€§æ£€æŸ¥:")
          ready_status = check_cluster_readiness(ssh, node)
          log("  é›†ç¾¤çŠ¶æ€: #{ready_status[:ready] ? 'âœ… å°±ç»ª' : 'â³ æœªå°±ç»ª'}")
          log("  è¯¦ç»†ä¿¡æ¯: #{ready_status[:status]}")

          # kubectl åŠŸèƒ½æµ‹è¯•
          log("\nğŸ§ª kubectl åŠŸèƒ½æµ‹è¯•:")
          kubectl_test = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && timeout 10 /var/lib/rancher/rke2/bin/kubectl get nodes --no-headers 2>/dev/null | wc -l').strip
          if kubectl_test.to_i > 0
            log("  âœ… kubectl æ­£å¸¸å·¥ä½œï¼Œå‘ç° #{kubectl_test} ä¸ªèŠ‚ç‚¹")
          else
            log('  âŒ kubectl æ— æ³•æ­£å¸¸å·¥ä½œ')
          end
        end
      rescue StandardError => e
        log("âŒ æ— æ³•è¿æ¥åˆ° #{node['name']}: #{e.message}")
      end
    end
  end

  def configure_ingress_daemonset
    log('ğŸ”§ é…ç½® Ingress Controller ä¸º DaemonSet æ¨¡å¼...')

    return if @server_nodes.empty?

    first_server = @server_nodes.first
    log("ğŸ“ åœ¨ #{first_server['name']} ä¸Šé…ç½® Ingress DaemonSet...")

    begin
      Net::SSH.start(first_server['ip'], first_server['ssh_user'], timeout: 30) do |ssh|
        # ç­‰å¾…é›†ç¾¤å°±ç»ª
        log('â³ ç­‰å¾…é›†ç¾¤ API å®Œå…¨å°±ç»ª...')
        wait_for_api_ready(ssh)

        # ç”Ÿæˆ Ingress DaemonSet é…ç½®
        ingress_config = generate_ingress_daemonset_manifest
        ssh.scp.upload!(StringIO.new(ingress_config), '/tmp/nginx-ingress-daemonset.yaml')

        log('ğŸš€ éƒ¨ç½² Nginx Ingress Controller (DaemonSet æ¨¡å¼)...')

        # åº”ç”¨é…ç½®
        output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl apply -f /tmp/nginx-ingress-daemonset.yaml 2>&1')
        log('ğŸ“‹ Ingress DaemonSet éƒ¨ç½²è¾“å‡º:')
        log(output)

        # ç­‰å¾… DaemonSet å°±ç»ª
        log('â³ ç­‰å¾… Ingress DaemonSet å°±ç»ª...')
        ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx rollout status daemonset/nginx-ingress-controller --timeout=300s')

        # éªŒè¯éƒ¨ç½²çŠ¶æ€
        log('ğŸ” éªŒè¯ Ingress Controller çŠ¶æ€...')
        status_output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx get daemonset,pods -o wide')
        log('ğŸ“Š Ingress Controller çŠ¶æ€:')
        log(status_output)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        ssh.exec!('rm -f /tmp/nginx-ingress-daemonset.yaml')

        log('âœ… Ingress Controller DaemonSet é…ç½®å®Œæˆ!')
      end
    rescue StandardError => e
      log("âŒ Ingress DaemonSet é…ç½®å¤±è´¥: #{e.message}")
      @logger.error("Ingress DaemonSet configuration failed: #{e.message}")
    end
  end

  def wait_for_api_ready(ssh)
    max_attempts = 20
    attempt = 0

    while attempt < max_attempts
      begin
        result = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && timeout 10 /var/lib/rancher/rke2/bin/kubectl get nodes >/dev/null 2>&1 && echo "ready"').strip
        if result == 'ready'
          log('âœ… API æœåŠ¡å™¨å·²å°±ç»ª')
          return true
        end
      rescue StandardError => e
        log("â³ ç­‰å¾… API å°±ç»ª... (#{attempt + 1}/#{max_attempts}): #{e.message}")
      end

      attempt += 1
      sleep(15)
    end

    log('âš ï¸ API æœåŠ¡å™¨ç­‰å¾…è¶…æ—¶ï¼Œä½†ç»§ç»­é…ç½®...')
    false
  end

  def generate_ingress_daemonset_manifest
    <<~YAML
      apiVersion: v1
      kind: Namespace
      metadata:
        name: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/instance: ingress-nginx
      ---
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: nginx-configuration
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      data:
        worker-processes: "auto"
        worker-connections: "16384"
        enable-real-ip: "true"
        use-gzip: "true"
        gzip-level: "6"
      ---
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: nginx-ingress-serviceaccount
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: nginx-ingress-clusterrole
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      rules:
        - apiGroups: [""]
          resources: ["configmaps", "endpoints", "nodes", "pods", "secrets", "namespaces"]
          verbs: ["list", "watch", "get"]
        - apiGroups: [""]
          resources: ["services"]
          verbs: ["get", "list", "watch"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingresses"]
          verbs: ["get", "list", "watch"]
        - apiGroups: [""]
          resources: ["events"]
          verbs: ["create", "patch"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingresses/status"]
          verbs: ["update"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingressclasses"]
          verbs: ["get", "list", "watch"]
        - apiGroups: ["coordination.k8s.io"]
          resources: ["leases"]
          verbs: ["list", "watch", "get", "update", "create"]
        - apiGroups: ["discovery.k8s.io"]
          resources: ["endpointslices"]
          verbs: ["list", "watch", "get"]
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: nginx-ingress-role
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      rules:
        - apiGroups: [""]
          resources: ["configmaps", "pods", "secrets", "namespaces"]
          verbs: ["get"]
        - apiGroups: [""]
          resources: ["configmaps"]
          resourceNames: ["ingress-controller-leader"]
          verbs: ["get", "update"]
        - apiGroups: [""]
          resources: ["configmaps"]
          verbs: ["create"]
        - apiGroups: ["coordination.k8s.io"]
          resources: ["leases"]
          verbs: ["get", "create", "update"]
        - apiGroups: [""]
          resources: ["endpoints"]
          verbs: ["get"]
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: nginx-ingress-role-nisa-binding
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: Role
        name: nginx-ingress-role
      subjects:
        - kind: ServiceAccount
          name: nginx-ingress-serviceaccount
          namespace: ingress-nginx
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: nginx-ingress-clusterrole-nisa-binding
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: nginx-ingress-clusterrole
      subjects:
        - kind: ServiceAccount
          name: nginx-ingress-serviceaccount
          namespace: ingress-nginx
      ---
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        name: nginx-ingress-controller
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/component: controller
      spec:
        selector:
          matchLabels:
            app.kubernetes.io/name: ingress-nginx
            app.kubernetes.io/part-of: ingress-nginx
            app.kubernetes.io/component: controller
        template:
          metadata:
            labels:
              app.kubernetes.io/name: ingress-nginx
              app.kubernetes.io/part-of: ingress-nginx
              app.kubernetes.io/component: controller
            annotations:
              prometheus.io/port: "10254"
              prometheus.io/scrape: "true"
          spec:
            serviceAccountName: nginx-ingress-serviceaccount
            hostNetwork: true
            dnsPolicy: ClusterFirstWithHostNet
            nodeSelector:
              kubernetes.io/os: linux
            tolerations:
            - key: node-role.kubernetes.io/control-plane
              operator: Exists
              effect: NoSchedule
            - key: node-role.kubernetes.io/master
              operator: Exists
              effect: NoSchedule
            containers:
            - name: nginx-ingress-controller
              image: registry.k8s.io/ingress-nginx/controller:v1.8.2
              args:
                - /nginx-ingress-controller
                - --configmap=$(POD_NAMESPACE)/nginx-configuration
                - --ingress-class=nginx
                - --watch-ingress-without-class=true
                - --http-port=80
                - --https-port=443
                - --healthz-port=10254
                - --enable-ssl-passthrough
              securityContext:
                allowPrivilegeEscalation: true
                capabilities:
                  drop: [ALL]
                  add: [NET_BIND_SERVICE]
                runAsUser: 101
                runAsGroup: 82
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
              ports:
              - name: http
                containerPort: 80
                hostPort: 80
                protocol: TCP
              - name: https
                containerPort: 443
                hostPort: 443
                protocol: TCP
              - name: webhook
                containerPort: 8443
                protocol: TCP
              - name: metrics
                containerPort: 10254
                protocol: TCP
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: 10254
                  scheme: HTTP
                initialDelaySeconds: 30
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 3
              readinessProbe:
                httpGet:
                  path: /healthz
                  port: 10254
                  scheme: HTTP
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 3
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 1000m
                  memory: 512Mi
      ---
      apiVersion: networking.k8s.io/v1
      kind: IngressClass
      metadata:
        name: nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      spec:
        controller: k8s.io/ingress-nginx
    YAML
  end

  # æ–°çš„çŠ¶æ€ç›‘æ§æ–¹æ³•
  def monitor_startup_progress(node, max_wait_minutes = 15)
    log("ğŸ”„ ç›‘æ§ #{node['name']} å¯åŠ¨è¿›åº¦ (æœ€å¤§ç­‰å¾… #{max_wait_minutes} åˆ†é’Ÿ)...")

    start_time = Time.now
    last_status = ''

    while (Time.now - start_time) < (max_wait_minutes * 60)
      begin
        Net::SSH.start(node['ip'], node['ssh_user'], timeout: 10) do |ssh|
          # è·å–æœ€æ–°çš„çŠ¶æ€æ¶ˆæ¯
          recent_log = ssh.exec!('journalctl -u rke2-server --no-pager -n 1 --since "30 seconds ago" -o cat 2>/dev/null | tail -1').strip

          if recent_log != last_status && !recent_log.empty?
            log("ğŸ“ #{Time.now.strftime('%H:%M:%S')}: #{recent_log}")
            last_status = recent_log
          end

          # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯é€€å‡º
          service_failed = ssh.exec!('systemctl is-failed rke2-server 2>/dev/null').strip
          if service_failed == 'failed'
            log('âŒ RKE2 æœåŠ¡å¤±è´¥,æ£€æŸ¥è¯¦ç»†æ—¥å¿—:')
            error_logs = ssh.exec!('journalctl -u rke2-server --no-pager -n 20 | tail -10')
            log(error_logs)
            return false
          end

          # æ£€æŸ¥æ˜¯å¦å·²å°±ç»ª
          ready_check = check_cluster_readiness(ssh, node)
          if ready_check[:ready]
            log("âœ… #{node['name']} å¯åŠ¨å®Œæˆ!")
            return true
          end
        end
      rescue StandardError => e
        log("âš ï¸  ç›‘æ§è¿æ¥é—®é¢˜: #{e.message}")
      end

      sleep(30)
    end

    log('â° ç›‘æ§è¶…æ—¶,ä½†è¿™ä¸ä¸€å®šæ„å‘³ç€å¤±è´¥')
    false
  end

  def deploy_to_node(node)
    ip = node['ip']
    user = node['ssh_user'] || 'root'
    name = node['name']
    role = node['role']

    log("ğŸ”— è¿æ¥ #{name} (#{ip}) - #{role}")

    begin
      Net::SSH.start(ip, user, timeout: 30) do |ssh|
        log("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶åˆ° #{name}...")
        ssh.exec!('mkdir -p /tmp')

        # ä¸Šä¼ é…ç½®æ–‡ä»¶
        if role == 'lb'
          ssh.scp.upload!("output/#{name}/haproxy.cfg", '/tmp/haproxy.cfg')
        else
          ssh.scp.upload!("output/#{name}/config.yaml", '/tmp/config.yaml')
        end

        # ä¸Šä¼ å®‰è£…è„šæœ¬
        ssh.scp.upload!("output/#{name}/install.sh", '/tmp/install.sh')

        log("âš™ï¸  åœ¨ #{name} ä¸Šæ‰§è¡Œå®‰è£…...")
        output = ssh.exec!('sudo bash /tmp/install.sh 2>&1')
        log("ğŸ“‹ #{name} å®‰è£…è¾“å‡º:")
        log(output)

        log("âœ… #{name} éƒ¨ç½²å®Œæˆ")
      end
    rescue StandardError => e
      log("âŒ #{name} éƒ¨ç½²å¤±è´¥: #{e.message}")
      @logger.error("#{name} deployment failed: #{e.message}")
      @logger.error(e.backtrace.join("\n"))
    end
  end

  # é…ç½®ç°æœ‰æœåŠ¡å™¨èŠ‚ç‚¹çš„ kubectl
  def configure_kubectl_on_servers
    log('ğŸ”§ é…ç½®æ‰€æœ‰æœåŠ¡å™¨èŠ‚ç‚¹çš„ kubectl...')

    @server_nodes.each do |node|
      configure_kubectl_on_node(node)
    end
  end

  # ä¸ºæ‰€æœ‰æœåŠ¡å™¨èŠ‚ç‚¹å®‰è£… k9s å’Œ helm
  def install_k9s_helm_on_servers
    log('ğŸ“¦ ä¸ºæ‰€æœ‰æœåŠ¡å™¨èŠ‚ç‚¹å®‰è£… k9s å’Œ helm...')

    @server_nodes.each do |node|
      install_k9s_helm_on_node(node)
    end
  end

  # ä¸ºå•ä¸ªèŠ‚ç‚¹å®‰è£… k9s å’Œ helm
  def install_k9s_helm_on_node(node)
    return unless node['role'] == 'server'

    log("ğŸ“¦ ä¸º #{node['name']} å®‰è£… k9s å’Œ helm...")

    begin
      Net::SSH.start(node['ip'], node['ssh_user'], timeout: 30) do |ssh|
        k9s_helm_script = <<~SH
                    #!/bin/bash
                    set -e
                    echo "ğŸ“¦ å®‰è£… k9s å’Œ helm åˆ° #{node['name']}..."

                    # å®‰è£… k9s
                    echo "ğŸ“¦ å®‰è£… k9s..."
                    K9S_VERSION=$(curl -s https://api.github.com/repos/derailed/k9s/releases/latest | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\\1/')
                    echo "  ä¸‹è½½ k9s $K9S_VERSION..."

                    # æ£€æµ‹ç³»ç»Ÿæ¶æ„
                    ARCH=$(uname -m)
                    case $ARCH in
                      x86_64) K9S_ARCH="amd64" ;;
                      aarch64) K9S_ARCH="arm64" ;;
                      *) K9S_ARCH="amd64" ;;
                    esac

                    curl -sL "https://github.com/derailed/k9s/releases/download/$K9S_VERSION/k9s_Linux_$K9S_ARCH.tar.gz" -o /tmp/k9s.tar.gz
                    tar -xzf /tmp/k9s.tar.gz -C /tmp
                    mv /tmp/k9s /usr/local/bin/k9s
                    chmod +x /usr/local/bin/k9s
                    rm -f /tmp/k9s.tar.gz /tmp/LICENSE /tmp/README.md

                    # éªŒè¯ k9s å®‰è£…
                    if k9s version >/dev/null 2>&1; then
                      echo "  âœ… k9s å®‰è£…æˆåŠŸ: $(k9s version --short)"
                    else
                      echo "  âš ï¸  k9s å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                    fi

                    # å®‰è£… helm
                    echo "ğŸ“¦ å®‰è£… helm..."
                    curl -fsSL -o /tmp/get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
                    chmod 700 /tmp/get_helm.sh
                    HELM_INSTALL_DIR="/usr/local/bin" /tmp/get_helm.sh --no-sudo >/dev/null 2>&1
                    rm -f /tmp/get_helm.sh

                    # éªŒè¯ helm å®‰è£…
                    if helm version >/dev/null 2>&1; then
                      echo "  âœ… helm å®‰è£…æˆåŠŸ: $(helm version --short)"
                    else
                      echo "  âš ï¸  helm å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                    fi

                    # åˆå§‹åŒ– helm
                    echo "ğŸ”§ åˆå§‹åŒ– helm..."
                    export KUBECONFIG=/root/.kube/config
                    helm repo add stable https://charts.helm.sh/stable >/dev/null 2>&1 || true
                    helm repo add bitnami https://charts.bitnami.com/bitnami >/dev/null 2>&1 || true
                    helm repo update >/dev/null 2>&1 || true
                    echo "  âœ… helm ä»“åº“åˆå§‹åŒ–å®Œæˆ"

                    # åˆ›å»º k9s é…ç½®ç›®å½•
                    echo "ğŸ”§ é…ç½® k9s..."
                    mkdir -p /root/.config/k9s

                    # åˆ›å»º k9s åŸºç¡€é…ç½®
                    cat > /root/.config/k9s/config.yml << 'EOF'
          k9s:
            liveViewAutoRefresh: true
            refreshRate: 2
            maxConnRetry: 5
            readOnly: false
            noExitOnCtrlC: false
            ui:
              enableMouse: true
              headless: false
              logoless: false
              crumbsless: false
              reactive: false
              noIcons: false
            skipLatestRevCheck: false
            disablePodCounting: false
            shellPod:
              image: busybox:1.35.0
              namespace: default
              limits:
                cpu: 100m
                memory: 100Mi
            imageScanner:
              enable: false
            logger:
              tail: 100
              buffer: 5000
              sinceSeconds: -1
              textWrap: false
              showTime: false
          EOF

                    echo ""
                    echo "ğŸ‰ k9s å’Œ helm å®‰è£…å®Œæˆï¼"
                    echo ""
                    echo "ğŸ’¡ å¯ç”¨å·¥å…·ï¼š"
                    echo "   kubectl get nodes          # Kubernetes å‘½ä»¤è¡Œå·¥å…·"
                    echo "   k get pods --all-namespaces # kubectl åˆ«å"
                    echo "   k9s                        # ç»ˆç«¯ UI é›†ç¾¤ç®¡ç†å·¥å…·"
                    echo "   helm list                  # Kubernetes åŒ…ç®¡ç†å™¨"
                    echo ""
                    echo "ğŸš€ k9s ä½¿ç”¨æç¤ºï¼š"
                    echo "   - æŒ‰ ':' è¿›å…¥å‘½ä»¤æ¨¡å¼"
                    echo "   - è¾“å…¥èµ„æºåç§°å¿«é€Ÿè·³è½¬ (pods, svc, deploy ç­‰)"
                    echo "   - æŒ‰ '?' æŸ¥çœ‹å¸®åŠ©"
                    echo "   - æŒ‰ 'Ctrl+C' é€€å‡º"
                    echo ""
        SH

        # ä¸Šä¼ å¹¶æ‰§è¡Œå®‰è£…è„šæœ¬
        ssh.scp.upload!(StringIO.new(k9s_helm_script), '/tmp/install_k9s_helm.sh')
        ssh.exec!('chmod +x /tmp/install_k9s_helm.sh')

        log("âš™ï¸  åœ¨ #{node['name']} ä¸Šå®‰è£… k9s å’Œ helm...")
        output = ssh.exec!('sudo bash /tmp/install_k9s_helm.sh 2>&1')
        log("ğŸ“‹ #{node['name']} k9s å’Œ helm å®‰è£…è¾“å‡º:")
        log(output)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        ssh.exec!('rm -f /tmp/install_k9s_helm.sh')

        log("âœ… #{node['name']} k9s å’Œ helm å®‰è£…å®Œæˆ")
      end
    rescue StandardError => e
      log("âŒ #{node['name']} k9s å’Œ helm å®‰è£…å¤±è´¥: #{e.message}")
      @logger.error("#{node['name']} k9s and helm installation failed: #{e.message}")
    end
  end

  # ä¸ºå•ä¸ªèŠ‚ç‚¹é…ç½® kubectl
  def configure_kubectl_on_node(node)
    return unless node['role'] == 'server'

    log("ğŸ”§ é…ç½® #{node['name']} çš„ kubectl...")

    begin
      Net::SSH.start(node['ip'], node['ssh_user'], timeout: 30) do |ssh|
        kubectl_config_script = <<~SH
                    #!/bin/bash
                    set -e
                    echo "ğŸ”§ é…ç½® kubectl for root ç”¨æˆ·..."

                    # æ£€æŸ¥ kubeconfig æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if [ ! -f /etc/rancher/rke2/rke2.yaml ]; then
                      echo "âŒ RKE2 kubeconfig æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ RKE2 å·²æ­£ç¡®å®‰è£…"
                      exit 1
                    fi

                    # åˆ›å»º kubectl è½¯é“¾æ¥åˆ°ç³»ç»Ÿ PATH
                    echo "ğŸ”— åˆ›å»º kubectl è½¯é“¾æ¥..."
                    ln -sf /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl
                    chmod +x /usr/local/bin/kubectl

                    # ä¸º root ç”¨æˆ·è®¾ç½® kubeconfig
                    echo "ğŸ“ ä¸º root ç”¨æˆ·é…ç½® kubeconfig..."
                    mkdir -p /root/.kube
                    cp /etc/rancher/rke2/rke2.yaml /root/.kube/config
                    chmod 600 /root/.kube/config
                    chown root:root /root/.kube/config

                    # è®¾ç½®ç¯å¢ƒå˜é‡åˆ° root çš„ bashrc
                    echo "ğŸ”§ é…ç½®ç¯å¢ƒå˜é‡..."
                    if ! grep -q "KUBECONFIG" /root/.bashrc; then
                      echo "# RKE2 kubectl configuration" >> /root/.bashrc
                      echo "export KUBECONFIG=/root/.kube/config" >> /root/.bashrc
                      echo "export PATH=/var/lib/rancher/rke2/bin:\\$PATH" >> /root/.bashrc
                      echo "alias k=kubectl" >> /root/.bashrc
                    fi

                    # è®¾ç½®ç¯å¢ƒå˜é‡åˆ° root çš„ profile
                    if ! grep -q "KUBECONFIG" /root/.profile; then
                      echo "# RKE2 kubectl configuration" >> /root/.profile
                      echo "export KUBECONFIG=/root/.kube/config" >> /root/.profile
                      echo "export PATH=/var/lib/rancher/rke2/bin:\\$PATH" >> /root/.profile
                    fi

                    # æµ‹è¯• kubectl é…ç½®
                    echo "ğŸ§ª æµ‹è¯• kubectl é…ç½®..."
                    export KUBECONFIG=/root/.kube/config
                    export PATH=/var/lib/rancher/rke2/bin:\\$PATH

                    # éªŒè¯ kubectl åŠŸèƒ½
                    echo "ğŸ” éªŒè¯ kubectl åŠŸèƒ½..."
                    if kubectl get nodes >/dev/null 2>&1; then
                      echo "âœ… kubectl é…ç½®æˆåŠŸï¼"
                      echo "ğŸ“Š å½“å‰é›†ç¾¤èŠ‚ç‚¹:"
                      kubectl get nodes
                    else
                      echo "âš ï¸  kubectl å¯èƒ½éœ€è¦ API æœåŠ¡å™¨å®Œå…¨å°±ç»ªåæ‰èƒ½æ­£å¸¸å·¥ä½œ"
                    fi

                    echo ""
                    echo "ğŸ‰ kubectl é…ç½®å®Œæˆï¼"
                    echo "ğŸ’¡ æç¤º: é‡æ–°ç™»å½• root ç”¨æˆ·åï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:"
                    echo "   kubectl get nodes"
                    echo "   k get pods --all-namespaces"
                    echo ""

                    # å®‰è£… k9s
                    echo "ğŸ“¦ å®‰è£… k9s..."
                    K9S_VERSION=$(curl -s https://api.github.com/repos/derailed/k9s/releases/latest | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\\1/')
                    echo "  ä¸‹è½½ k9s $K9S_VERSION..."

                    # æ£€æµ‹ç³»ç»Ÿæ¶æ„
                    ARCH=$(uname -m)
                    case $ARCH in
                      x86_64) K9S_ARCH="amd64" ;;
                      aarch64) K9S_ARCH="arm64" ;;
                      *) K9S_ARCH="amd64" ;;
                    esac

                    curl -sL "https://github.com/derailed/k9s/releases/download/$K9S_VERSION/k9s_Linux_$K9S_ARCH.tar.gz" -o /tmp/k9s.tar.gz
                    tar -xzf /tmp/k9s.tar.gz -C /tmp
                    mv /tmp/k9s /usr/local/bin/k9s
                    chmod +x /usr/local/bin/k9s
                    rm -f /tmp/k9s.tar.gz /tmp/LICENSE /tmp/README.md

                    # éªŒè¯ k9s å®‰è£…
                    if k9s version >/dev/null 2>&1; then
                      echo "  âœ… k9s å®‰è£…æˆåŠŸ: $(k9s version --short)"
                    else
                      echo "  âš ï¸  k9s å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                    fi

                    # å®‰è£… helm
                    echo "ğŸ“¦ å®‰è£… helm..."
                    curl -fsSL -o /tmp/get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
                    chmod 700 /tmp/get_helm.sh
                    HELM_INSTALL_DIR="/usr/local/bin" /tmp/get_helm.sh --no-sudo >/dev/null 2>&1
                    rm -f /tmp/get_helm.sh

                    # éªŒè¯ helm å®‰è£…
                    if helm version >/dev/null 2>&1; then
                      echo "  âœ… helm å®‰è£…æˆåŠŸ: $(helm version --short)"
                    else
                      echo "  âš ï¸  helm å®‰è£…å¯èƒ½æœ‰é—®é¢˜"
                    fi

                    # åˆå§‹åŒ– helm
                    echo "ğŸ”§ åˆå§‹åŒ– helm..."
                    export KUBECONFIG=/root/.kube/config
                    helm repo add stable https://charts.helm.sh/stable >/dev/null 2>&1 || true
                    helm repo add bitnami https://charts.bitnami.com/bitnami >/dev/null 2>&1 || true
                    helm repo update >/dev/null 2>&1 || true
                    echo "  âœ… helm ä»“åº“åˆå§‹åŒ–å®Œæˆ"

                    # åˆ›å»º k9s é…ç½®ç›®å½•
                    echo "ğŸ”§ é…ç½® k9s..."
                    mkdir -p /root/.config/k9s

                    # åˆ›å»º k9s åŸºç¡€é…ç½®
                    cat > /root/.config/k9s/config.yml << 'EOF'
          k9s:
            liveViewAutoRefresh: true
            refreshRate: 2
            maxConnRetry: 5
            readOnly: false
            noExitOnCtrlC: false
            ui:
              enableMouse: true
              headless: false
              logoless: false
              crumbsless: false
              reactive: false
              noIcons: false
            skipLatestRevCheck: false
            disablePodCounting: false
            shellPod:
              image: busybox:1.35.0
              namespace: default
              limits:
                cpu: 100m
                memory: 100Mi
            imageScanner:
              enable: false
            logger:
              tail: 100
              buffer: 5000
              sinceSeconds: -1
              textWrap: false
              showTime: false
          EOF

                    echo ""
                    echo "ğŸ‰ k9s å’Œ helm å®‰è£…å®Œæˆï¼"
                    echo ""
                    echo "ğŸ’¡ å¯ç”¨å·¥å…·ï¼š"
                    echo "   kubectl get nodes          # Kubernetes å‘½ä»¤è¡Œå·¥å…·"
                    echo "   k get pods --all-namespaces # kubectl åˆ«å"
                    echo "   k9s                        # ç»ˆç«¯ UI é›†ç¾¤ç®¡ç†å·¥å…·"
                    echo "   helm list                  # Kubernetes åŒ…ç®¡ç†å™¨"
                    echo ""
                    echo "ğŸš€ k9s ä½¿ç”¨æç¤ºï¼š"
                    echo "   - æŒ‰ ':' è¿›å…¥å‘½ä»¤æ¨¡å¼"
                    echo "   - è¾“å…¥èµ„æºåç§°å¿«é€Ÿè·³è½¬ (pods, svc, deploy ç­‰)"
                    echo "   - æŒ‰ '?' æŸ¥çœ‹å¸®åŠ©"
                    echo "   - æŒ‰ 'Ctrl+C' é€€å‡º"
                    echo ""
        SH

        # ä¸Šä¼ å¹¶æ‰§è¡Œé…ç½®è„šæœ¬
        ssh.scp.upload!(StringIO.new(kubectl_config_script), '/tmp/configure_kubectl.sh')
        ssh.exec!('chmod +x /tmp/configure_kubectl.sh')

        log("âš™ï¸  åœ¨ #{node['name']} ä¸Šé…ç½® kubectl...")
        output = ssh.exec!('sudo bash /tmp/configure_kubectl.sh 2>&1')
        log("ğŸ“‹ #{node['name']} kubectl é…ç½®è¾“å‡º:")
        log(output)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        ssh.exec!('rm -f /tmp/configure_kubectl.sh')

        log("âœ… #{node['name']} kubectl é…ç½®å®Œæˆ")
      end
    rescue StandardError => e
      log("âŒ #{node['name']} kubectl é…ç½®å¤±è´¥: #{e.message}")
      @logger.error("#{node['name']} kubectl configuration failed: #{e.message}")
    end
  end

  def fix_ingress_rbac
    log('ğŸ”§ ä¿®å¤ Ingress Controller RBAC æƒé™...')

    return if @server_nodes.empty?

    first_server = @server_nodes.first
    log("ğŸ“ åœ¨ #{first_server['name']} ä¸Šä¿®å¤ Ingress RBAC æƒé™...")

    begin
      Net::SSH.start(first_server['ip'], first_server['ssh_user'], timeout: 30) do |ssh|
        # ç­‰å¾…é›†ç¾¤å°±ç»ª
        log('â³ ç­‰å¾…é›†ç¾¤ API å®Œå…¨å°±ç»ª...')
        wait_for_api_ready(ssh)

        # ç”Ÿæˆä¿®å¤çš„ RBAC é…ç½®
        rbac_fix_config = generate_rbac_fix_manifest
        ssh.scp.upload!(StringIO.new(rbac_fix_config), '/tmp/nginx-ingress-rbac-fix.yaml')

        log('ğŸš€ åº”ç”¨ä¿®å¤çš„ RBAC æƒé™...')

        # åº”ç”¨é…ç½®
        output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl apply -f /tmp/nginx-ingress-rbac-fix.yaml 2>&1')
        log('ğŸ“‹ RBAC ä¿®å¤è¾“å‡º:')
        log(output)

        # é‡å¯ Ingress Pod ä»¥åº”ç”¨æ–°æƒé™
        log('ğŸ”„ é‡å¯ Ingress Controller Pods...')
        restart_output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx rollout restart daemonset/nginx-ingress-controller 2>&1')
        log(restart_output)

        # ç­‰å¾…é‡å¯å®Œæˆ
        log('â³ ç­‰å¾… Ingress Pods é‡å¯å®Œæˆ...')
        ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx rollout status daemonset/nginx-ingress-controller --timeout=300s')

        # éªŒè¯ä¿®å¤çŠ¶æ€
        log('ğŸ” éªŒè¯ Ingress Controller çŠ¶æ€...')
        status_output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx get pods')
        log('ğŸ“Š Ingress Controller çŠ¶æ€:')
        log(status_output)

        # æ£€æŸ¥æƒé™æ˜¯å¦ä¿®å¤
        log('ğŸ§ª æµ‹è¯•æƒé™ä¿®å¤...')
        test_output = ssh.exec!('export KUBECONFIG=/etc/rancher/rke2/rke2.yaml && /var/lib/rancher/rke2/bin/kubectl -n ingress-nginx logs daemonset/nginx-ingress-controller --tail=10 2>&1 | grep -E "(error|Error|forbidden|Forbidden)" || echo "No permission errors found"')
        log("æƒé™æµ‹è¯•ç»“æœ: #{test_output}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        ssh.exec!('rm -f /tmp/nginx-ingress-rbac-fix.yaml')

        log('âœ… Ingress Controller RBAC æƒé™ä¿®å¤å®Œæˆ!')
      end
    rescue StandardError => e
      log("âŒ Ingress RBAC æƒé™ä¿®å¤å¤±è´¥: #{e.message}")
      @logger.error("Ingress RBAC fix failed: #{e.message}")
    end
  end

  def generate_rbac_fix_manifest
    <<~YAML
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: nginx-ingress-clusterrole
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      rules:
        - apiGroups: [""]
          resources: ["configmaps", "endpoints", "nodes", "pods", "secrets", "namespaces"]
          verbs: ["list", "watch", "get"]
        - apiGroups: [""]
          resources: ["services"]
          verbs: ["get", "list", "watch"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingresses"]
          verbs: ["get", "list", "watch"]
        - apiGroups: [""]
          resources: ["events"]
          verbs: ["create", "patch"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingresses/status"]
          verbs: ["update"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingressclasses"]
          verbs: ["get", "list", "watch"]
        - apiGroups: ["coordination.k8s.io"]
          resources: ["leases"]
          verbs: ["list", "watch", "get", "update", "create"]
        - apiGroups: ["discovery.k8s.io"]
          resources: ["endpointslices"]
          verbs: ["list", "watch", "get"]
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: nginx-ingress-role
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      rules:
        - apiGroups: [""]
          resources: ["configmaps", "pods", "secrets", "namespaces"]
          verbs: ["get"]
        - apiGroups: [""]
          resources: ["configmaps"]
          resourceNames: ["ingress-controller-leader"]
          verbs: ["get", "update"]
        - apiGroups: [""]
          resources: ["configmaps"]
          verbs: ["create"]
        - apiGroups: ["coordination.k8s.io"]
          resources: ["leases"]
          verbs: ["get", "create", "update"]
        - apiGroups: [""]
          resources: ["endpoints"]
          verbs: ["get"]
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: nginx-ingress-role-nisa-binding
        namespace: ingress-nginx
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: Role
        name: nginx-ingress-role
      subjects:
        - kind: ServiceAccount
          name: nginx-ingress-serviceaccount
          namespace: ingress-nginx
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: nginx-ingress-clusterrole-nisa-binding
        labels:
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: nginx-ingress-clusterrole
      subjects:
        - kind: ServiceAccount
          name: nginx-ingress-serviceaccount
          namespace: ingress-nginx
    YAML
  end
end
